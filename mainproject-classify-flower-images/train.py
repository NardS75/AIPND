#!/usr/bin/env python3
# -*- coding: utf-8 -*-
#
# PROGRAMMER: Vittorio Nardone
# DATE CREATED: 05/07/2018
# REVISED DATE:             <=(Date Revised - if any)
# PURPOSE: Train a new deep neural network on a image dataset and save
#          the model as a checkpoint.
#          Pre-trained networks are used (VGG/Densenet)
#
# Expected Call with <> indicating expected user input:
#      python train.py <directory with images>
#             --save_dir <directory to save checkpoint file>
#             --checkpoint <filename>
#             --arch <model>
#             --learning_rate <train learning rate>
#             --hidden_units <model hidden units>
#             --epochs <train epochs>
#             --gpu
#             --dropout <probability>
#
# Example call:
#    python train.py flowers/ --epochs 7 --gpu
#    python train.py flowers/ --save_dir checkpoints/ --arch vgg11 --hidden_units 1024,1024 --dropout 0.5 --gpu
#    python train.py flowers/ --checkpoint cp_densenet201.pth --arch densenet201 --gpu
#    python train.py flowers/ --arch alexnet
#
# Arguments explaination:
# <directory with images>    (required)
#     Expected folder strucure:
#        - "train" subfolder is used to train the model
#        - "valid" subfolder is used to validate the model
#     In both "train" & "valid" folders, class subfolders with sample images
#     are expected. Class subfolder name is used as class name.
#
# --save_dir <directory to save checkpoint file> (optional, default is current folder)
#     Trained model checkpoint file is saved in specified directory
#
# --checkpoint <filename> (optional, default is autogenerated)
#     Trained model checkpoint file is saved with specified filename
#     Default autogenerated filename includes arch name, epochs count and learning rate
#
# --arch <model> (optional, default is "densenet121")
#     Pretrained model architecture: 'densenet121', 'densenet161', 'densenet169', 'densenet201',
#                                    'vgg11', 'vgg13', 'vgg16', 'vgg19',
#                                    'vgg11_bn', 'vgg13_bn', 'vgg16_bn', 'vgg19_bn', 'alexnet'
#
# --learning_rate <train learning rate> (optional, default is "0.05")
#     Model training learning rate
#
# --hidden_units <model hidden units> (optional, default no hidden units)
#     Specify hidden layers units in classifier. ReLU is added automatically.
#         --hidden_units = 1024 (add one hidden layer with 1024 units)
#         --hidden_units = 1024,512 (add two hidden layers with 1024 and 512 units
#
# --epochs <train epochs> (optional, default is 10 or validation accuracy >= 85%)
#     Model training epochs. If not set, training process stop after 10 epochs or
#     before if validation accuracy become greater than 80%
#
# --gpu (optional, default "cpu")
#     If set, GPU is used to train the model
#
# --dropout (optional, default no dropout)
#     Add specified probability dropout between classifier layers
#
# Imports python modules
import argparse
import os.path
from time import time, gmtime, strftime

import model_helper_keras as mh

# Main program function defined below
def main():
    #Collect start time
    start_time = time()

    #Parse command line arguments
    in_arg = get_input_args()

    #Model Training
    model = model_training(in_arg)

    #Save checkpoint
    mh.save_checkpoint(model, in_arg.save_dir, filename = in_arg.checkpoint)

    tot_time = time() - start_time
    print("\n** Total Elapsed Runtime:", strftime("%H:%M:%S", gmtime(tot_time)))

# Command line arguments parser
def get_input_args():
    """
    Retrieves and parses the command line arguments created and defined using
    the argparse module. This function returns these arguments as an
    ArgumentParser object.
    Parameters:
     None - simply using argparse module to create & store command line arguments
    Returns:
     parse_args() -data structure that stores the command line arguments object
    """
    # create arguments parser
    parser = argparse.ArgumentParser()

    parser.add_argument("data_dir", nargs=1, type = str,
                    help = "Directory including training ('train') and validation ('valid') images subdirectories. Class named subfolders are expected.")
    parser.add_argument('--save_dir', type = str, default = '',
                    help = "Trained model checkpoint file is saved in specified directory (default: current directory)")
    parser.add_argument('--checkpoint', type = str, default = '',
                    help = "Trained model checkpoint filename (default: autogenerated)")
    parser.add_argument('--arch', type = str, choices=mh.supported_models(), default = 'densenet121',
                    help = "Pretrained model architecture to be used for image classification (default: 'densenet121')")
    parser.add_argument('--learning_rate', type = float, default = 0.05,
                    help = "Model training learning rate (default: 0.05)")
    parser.add_argument('--hidden_units', type = str, default = '',
                    help = "Hidden layer units in classifier. Example: --hidden_units = 1024 (add one hidden layer with 1024 units) --hidden_units = 1024,512 (add two hidden layers with 1024 and 512 units) (default: no hidden layers)")
    parser.add_argument('--epochs', type = int, default = 0,
                    help = "Model training epochs. If not set, training process stops after 10 epochs or 0.85 accuracy reached")
    parser.add_argument('--full_net_epochs', type = int, default = 0,
                    help = "Full net training epochs. If not set, no full net training is performed")
    parser.add_argument('--batch_size', type = int, default = 64,
                    help = "Model training batch size")
    parser.add_argument('--gpu', action='store_true',
                    help = "If set, GPU is used to train the model (default: False)")
    parser.add_argument('--dropout', type = float, default = 0,
                    help = "Add specified probability Dropout between classifier layers (default: no dropout)")
    parser.add_argument('--bn', action='store_true',
                    help = "Add batch normalization layer in classifier (default: no)")
    parser.add_argument('--optimizer', type = str, choices=mh.supported_optimizer(), default = 'SGD',
                    help = "Set optimizer to be used (default: 'SGD')")

    in_arg = parser.parse_args()

    # If epochs is not set, define default values
    if in_arg.epochs == 0:
        in_arg.epochs = 10
        in_arg.min_accuracy = 0.85
    else:
        in_arg.min_accuracy = 1

    error_list = []

    # Transform hidden_units from (csv) string to array of int
    in_arg.hidden_units = in_arg.hidden_units.split(',')
    try:
        in_arg.hidden_units = [int(s) for s in in_arg.hidden_units if s != '']
    except:
        error_list.append("train.py: error: argument: --hidden_units: must be int or a comma separated list of int")

    # Check data directories
    in_arg.data_dir = in_arg.data_dir[0]

    train_folder = os.path.normpath("{}/train".format(in_arg.data_dir))
    valid_folder = os.path.normpath("{}/valid".format(in_arg.data_dir))
    if not os.path.isdir(train_folder) or not os.path.isdir(valid_folder):
        error_list.append("train.py: error: argument: data_dir: subfolder 'train' or 'valid' not found")

    # Check destination directory
    if in_arg.save_dir != '':
        if not os.path.isdir(in_arg.save_dir):
            error_list.append("train.py: error: argument: --save_dir: directory '{}' not found".format(in_arg.save_dir))

    # Check hyperparamters
    if in_arg.epochs <= 0:
        error_list.append("train.py: error: argument: --epochs: must be positive int")

    if in_arg.learning_rate <= 0:
        error_list.append("train.py: error: argument: --learning_rate: must be positive float")

    if in_arg.dropout < 0 or in_arg.dropout >= 1:
        error_list.append("train.py: error: argument: --dropout: must be float in range (0,1)")

    # Check GPU
    if in_arg.gpu and not mh.gpu_available():
        error_list.append("train.py: error: argument: --gpu: GPU not available")

    # Print errors
    if len(error_list) > 0:
        parser.print_usage()
        print('\n'.join(error for error in error_list))
        quit()

    # return arguments object
    return in_arg

# Define, configure and train the model
def model_training(in_arg):
    """
    Define, configure and train the model. Progress is shown during training.
    Parameters:
     in_arg - data structure that stores the command line arguments object
    Returns:
     model - the trained model object
    """
    model = mh.create_and_train(in_arg.data_dir,
                                arch = in_arg.arch,
                                hidden_units = in_arg.hidden_units,
                                epochs = in_arg.epochs,
                                learning_rate = in_arg.learning_rate,
                                accuracy = in_arg.min_accuracy,
                                gpu_mode = in_arg.gpu,
                                dropout = in_arg.dropout,
                                bn = in_arg.bn,
                                optimization = in_arg.optimizer,
                                batch_size = in_arg.batch_size,
                                full_net_epochs = in_arg.full_net_epochs)
    return model


# Call to main function to run the program
if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n** User interruption")
        quit()
